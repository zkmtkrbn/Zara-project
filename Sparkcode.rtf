{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue255;\red255\green255\blue254;\red19\green118\blue70;
\red157\green0\blue210;\red144\green1\blue18;\red32\green108\blue135;\red15\green112\blue1;\red255\green255\blue255;
\red0\green0\blue0;\red255\green255\blue254;\red101\green76\blue29;\red144\green1\blue18;\red32\green108\blue135;
}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c100000;\cssrgb\c100000\c100000\c99608;\cssrgb\c3529\c52549\c34510;
\cssrgb\c68627\c0\c85882;\cssrgb\c63922\c8235\c8235;\cssrgb\c14902\c49804\c60000;\cssrgb\c0\c50196\c0;\cssrgb\c100000\c100000\c100000;
\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c99608;\cssrgb\c47451\c36863\c14902;\cssrgb\c63922\c8235\c8235;\cssrgb\c14902\c49804\c60000;
}
\margl1440\margr1440\vieww25480\viewh25160\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
!\cf0 apt-get install openjdk-\cf4 8\cf0 -jdk-headless -qq > /dev/null\cb1 \
\cf2 \cb3 !\cf0 wget -q http://archive.apache.org/dist/spark/spark-\cf4 3.1.1\cf0 /spark-\cf4 3.1.1\cf0 -bin-hadoop3\cf4 .2\cf0 .tgz\cb1 \
\cf2 \cb3 !\cf0 tar xf spark-\cf4 3.1.1\cf0 -bin-hadoop3\cf4 .2\cf0 .tgz\cb1 \
\cf2 \cb3 !\cf0 pip install -q findspark\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 import\cf0  os\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 os.environ[\cf6 "JAVA_HOME"\cf0 ] = \cf6 "/usr/lib/jvm/java-8-openjdk-amd64"\cf0 \cb1 \
\cb3 os.environ[\cf6 "SPARK_HOME"\cf0 ] = \cf6 "/content/spark-3.1.1-bin-hadoop3.2"\cf0 \cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 import\cf0  findspark\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 findspark.init()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 from\cf0  pyspark.sql \cf5 import\cf0  SparkSession\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 spark = SparkSession.builder.master(\cf6 "local[*]"\cf0 ).getOrCreate()\cb1 \
\cb3 spark.conf.\cf7 set\cf0 (\cf6 "spark.sql.repl.eagerEval.enabled"\cf0 , \cf2 True\cf0 ) \cf8 # Property used to format output tables better\cf0 \cb1 \
\cb3 spark\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf8 \cb3 # Load the csv into a dataframe\cf0 \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb3 Zara_df = spark.read.csv(\cf6 \'93Zara.csv"\cf0 , header=\cf2 True\cf0 , inferSchema=\cf2 True\cf0 )\cb1 \
\cb3 Zara_df\cb1 \
\
\
\cb3 Zara_df.printSchema()\
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb9 root\
 |-- NAME: string (nullable = true)\
 |-- SKU: integer (nullable = true)\
 |-- MPN: integer (nullable = true)\
 |-- BRAND: string (nullable = true)\
 |-- DESCRIPTION: string (nullable = true)\
 |-- PRICE: integer (nullable = true)\
 |-- CURRENCY: string (nullable = true)\
 |-- AVAILABILITY: string (nullable = true)\
 |-- CONDITION: string (nullable = true)\
 |-- COLOR: string (nullable = true)\
 |-- SIZE_LIST: string (nullable = true)\
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb11 \outl0\strokewidth0 \strokec10 zara_df.show()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf12 \cb11 \strokec12 \
\
print\cf0 \cb11 \strokec10 (\cf13 \cb11 \strokec13 "Number of records: "\cf0 \cb11 \strokec10  + \cf14 \cb11 \strokec14 str\cf0 \cb11 \strokec10 (zara_df.count()))\
Number of record: 4475
\f1\fs26\fsmilli13333 \cb1 \strokec10 \
}